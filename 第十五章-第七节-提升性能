	词组和临近词查询要比简单的match查询的花销更为昂贵。尽管match查询仅仅在反响索引中查找短语，match_phrase查询则必须要计算和比较多个可能重复出现的短语的位置。Lucene每日校准显示一个简单的短语查询要比词组查询快10倍，比临近词查询快20倍。而这些花销都是在搜索的时候产生的。
	通常情况下，词组查询的额外耗费并不是想数字显示的那样的可怕。事实上，这只是显示了简单的短语查询非常快的一个证据。词组查询在典型的全文本数据中通常会在几毫秒内完成，并且在实际应用中可以被用于负担比较重的集群中。
	在特定的异常事件中，词组查询可能会非常的昂贵，不过这个不常发生。举例来说，DNA测序就是这么一个情况，其中会有很多一样的短语在多处重复出现。这时使用高的slop值将会导致位置计算的数量大幅提高。
	那么，对于词组和临近词查询有什么办法可以提高性能呢？一个有用的方法就是减少需要通过词组查询检查的文档的总数。
	之前只对如何使用临近词查询来提高关联度而没有把文档加入或者清除出结果集。一个查询可能匹配百万级的结果，不过事实上，用户往往只对前几页有兴趣。一个简单的match查询已经把包含所有短语的文档排在了列表的顶部。所以只需要把顶部的结果再次排序，把匹配词组查询的文档的排序提升一下就可以了。
	search API可以通过rescoring支持这样的功能，重新打分语法允许你应用一个花销更为昂贵的打分算法，比如词组查询，这个算法只是对每个分片的顶部的K歌结果进行计算。这些顶部的结果接下来会按照新的得分重新排序：
	GET /my_index/my_type/_search
	{
	    "query": {
	        "match": {  //Match查询决定有哪些文档会被加入到结果集中，并且是按照tf/idf排序的
	            "title": {
	                "query":                "quick brown fox",
	                "minimum_should_match": "30%"
	            }
	        }
	    },
	    "rescore": {
	        "window_size": 50, //需要被重新打分的每个分片的前k个结果，
	        "query": {         //目前只支持查询作为重新打分的算法
	            "rescore_query": {
	                "match_phrase": {
	                    "title": {
	                        "query": "quick brown fox",
	                        "slop":  50
	                    }
	                }
	            }
	        }
	    }
	}
