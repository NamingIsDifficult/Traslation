	不使用fsync来讲文件系统缓存里的数据冲刷到硬盘中的话，我们并不能保证数据在掉电甚至是应用退出的时候不会丢失。为了保证Elasticsearch的可用性，它需要将变更持久化到硬盘中
	前文提及到一次完整的提交将分段冲刷到硬盘并且写入一个提交点，其中列出了所有的分段。Elasticsearch在开启或重新打开一个索引时使用提交点来分辨哪些分段属于当前分片。
	当使用每秒一次刷新来达成近似实时搜索的功能的时候，依旧要按照规律做完整的提交来保证当异常发生的时候可以恢复。那么，在提交的时候发生的文档变更是怎么处理的呢？
	Elasticsearch添加一个translog，即事务日志，其中记录了Elasticsearch中发生的每个操作。通过事务日志，进程如下：
	1.当一个文档被索引的时候，它被添加到内存中的缓冲区然后再添加到事务日志中。
	2.刷新的时候缓冲区被清空，但是事务日志没有被清空，每秒分片都会被刷新：
		2.1 内存缓冲区中的文档被写入到新的分段中，并且不会执行fsync
		2.2 分段是被打开的，这样才能被搜索可见
		2.3 内存缓冲区被清空
	3.越来越多的文档添加进来，重复1-2
	4.每当事务日志变得过大的时候，索引就会被冲刷到硬盘，然后一个新的事务日志会被创建，并且执行一次完整的提交。
		4.1 任意在内存缓冲区中的文档被写入到新的分段中
		4.2 缓冲区被清空
		4.3 一个提交点被写入到硬盘
		4.4 文件系统缓存通过fsync冲刷至硬盘
		4.5 旧的事务日志被删除
	事务日志提供了所有还未被冲刷到硬盘的操作的持久化记录，当搜索引擎启动的时候，Elasticsearch会使用最近一次的提交点来从磁盘恢复已知的分段，然后再通过事务日志中的操作把最近一次提交点之后的变更添加进来。
	事务日志页用来支持实时CRUD的功能，当尝试使用ID来对一个文档做CRUD的时候，在从关联分段中获取文档之前，它先去事务日志中检查是否有变更。这意味着它总能实时进入到最新版本的文档中。
	执行提交比国内且清除事务日志的操作在Elasticsearch中被称为冲刷(flush)。分片每30分钟就会自动冲刷一次，或者在事务日志过大时执行。后续章节会详细如何设置事务日志。
	可以手动执行flush API来冲刷：
	POST /blogs/_flush //冲刷blogs索引

	POST /_flush?wait_for_ongoing  //冲刷所有的索引，并且在全部完成之前一直等待
	很少有需要手动冲刷的情形发生；通常情况下，自动冲刷就可以解决大多数问题了。
	即便如此，在启动一个节点或是关闭一个索引之前冲刷索引还是有好处的。当Elasticsearch尝试恢复或是重新启动索引的时候，它还是会重新执行事务日志中的所有操作，所以日志越短，恢复就越快。
	事务日志的目的是为了使所有的变更都不会因为异常而丢失，那么，事务日志到底有没有这么安全呢？
	在重启之前如果不使用fsync的话，即使把变更写入到文件中也是会丢失的。默认情况下，事务日志每5秒钟就会在一次写请求结束后执行fsync。这个进程在基本分片和复制分片上都一样会被执行。基本上，这意味着基本分片和复制分片中的事务日志如果没有全部被fsync盗磁盘的话就接收不到200响应。
	尽管每个请求之后都执行fsync对性能还是有影响的，但是在实际应用中相对来说较小。尤其是对批量操作，它把耗费的资源分摊到各个文档中，要比单个单个执行好的多。
	但是对于某些大容量并且对数据实时性要求不那么高的集群来说，使用异步的fsync效果会比较好。这意味着写入将会缓冲在内存中并且每5秒钟被一起同步到文件系统中。
	这些行为可以通过设置async的参数为durability来实现：
	PUT /my_index/_settings
	{
	    "index.translog.durability": "async",
	    "index.translog.sync_interval": "5s"
	}
	可以给每个索引都设置不同的参数，并且可以动态更新。如果你决定要使用异步同步事务日志到文件系统的话，意味着当系统崩溃的时候会丢失sync_interval范围内的数据。所以务必注意这一点。
	如果你对这个操作的副作用不知如何取舍的话，最好还是使用默认设置，即每次请求都使用文件同步来保证不会丢失数据。"index.translog.durability": "request"
	
	
