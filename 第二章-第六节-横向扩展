	如果系统成长到了不得不扩容的地步，我们可以再开启第三个节点，集群会将节点中的分片重新分配如下：
	Cluster:Node1-*master		Node2		Node3
			P1	P2				R0	R1		P0	R2
	节点1和节点2均有一个分片分配到了节点3，这样每个节点中就有了2个分片，而不是原来的3个。这意味着每个节点中的分片都可以享用相对更多的硬件资源（CPU，RAM,I/O），相应的性能也会提高。
	一个分片本身就是一个成熟的搜索引擎，它有运用单个节点中的所有资源的能力。在有6个分片的情况下（3个基本分片，3个复制分片），索引可以被扩展至最多6个节点，每个节点上会被分配一个分片，每个分片都有100%的节点资源供其使用。
	如何扩展到超过6个的节点呢？当索引创建的时候就分配了固定数量的基本分片。实际上，这个数量也定义了索引所能存储数据数量的上限。实际的数量取决于你的数据情况，你的硬件情况，以及使用状况。但是，读取请求--搜索和文档获取是可以被基本分片或者复制分片处理的，所以拷贝的数量越多，系统就可以处理越多的搜索产量。
	在一个活跃的集群中，复制分片的数量是可以动态修改的，让我们可以在需求变化的时候扩容或缩减。修改分片数量的命令如下：
	PUT /blogs/_settings
	{
	   "number_of_replicas" : 2
	}
	效果如下：
	Cluster:Node1-*master			Node2				Node3
			R0	P1	P2				R0	R1	R2			P0	R1	R2
	blogs索引现在有9个分片：3个基本分片和6个复制分片。这意味着我们可以扩容至最多9个节点，同样是每个节点都有一个分片。这使得搜索的性能与只有1个节点的时候相比提高了3倍。
	小贴士：当然，只是在节点上添加复制分片是不会提升性能的，因为每个分片因此也会拥有更少的节点资源，你需要通过提升硬件来增加吞吐量。
	但这些额外添加的复制分片确实意味着提升了系统的冗余度：通过这种节点的配置，即使有两个节点失效了，我们也不会丢失任何数据。
