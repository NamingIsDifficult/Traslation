	Lucene使用布尔模型来查找匹配的文档，并且使用一个叫做实用打分方法的公式来计算关联程度。这个公式借鉴了tf/idf和向量空间模型的理念，不过，其中还添加了更为现代的特性，比如坐标向量，字段长度标准化，短语或者查询子句权重提升等。
	布尔模型：
	这个模型使用了与或非三种逻辑操作来处理查询，以此来查找匹配的文档，一个类似的查询如下：
	full AND text AND search AND (elasticsearch OR lucene)
	这个查询用于查找包含full, text,  search并且包含elasticsearch 或 lucene的文档。这个过程很简单，也很快捷。它用于排除任意不匹配查询的文档。
	短语频率/反向文档频率(tf/idf)
	一旦有了一个匹配文档的列表，它们就需要按照关联度进行排序。并不是所有的文档都会包含所有的短语，而且有一些短语的权重根据需求还会相应提高。整个文档的关联分与文档中出现的查询短语的权重部分相关。
	一个短语的权重取决于3个参数，这个在前面的章节中介绍过了。
	tf/短语频率
	这个短语在这个文档中出现的频率是多少？出现的越多，权重就越大。短语频率的计算方式如下：
	tf(t in d) = √frequency 短语t在文档d中的短语频率是它出现的频次的开根。
	如果你并不关注短语在字段中出现的频率，只要出现就可以，那么就可以取消该字段中短语频率的计算：
	PUT /my_index
	{
	  "mappings": {
	    "doc": {
	      "properties": {
	        "text": {
	          "type":          "string",
	          "index_options": "docs" //这个设置将会移除短语频率和短语位置的计算。这样的字段将不支持词组和临近词查询。类型是not_analyz											ed的精确值字串字段使用这个默认设置。
	        }
	      }
	    }
	  }
	}
	idf/反向文档频率
	结果集中短语在各文档中的是否出现的频率是多少？越多，权重越低。类似and,or之类的普通的短语对于关联分的影响微乎其微，因为大多数文档中都有这些词，而像elastic或者hippopotamus之类的不常见的词将会帮助聚焦到感兴趣的文档上去。反向文档频率的计算方式如下：
	idf(t) = 1 + log ( numDocs / (docFreq + 1)) //短语t的反向索引频率idf是索引中的文档数量除以包含该短语的文档数量再求对数
	字段长度规范化
	字段的长度是多少？越短，权重越高。计算方法如下：
	norm(d) = 1 / √numTerms //字段中短语的数量的根号分之一
	
