	按照自动刷新的进程，每秒钟都会创建一个新的分段，这样的话不要多久数量就要爆炸了！分段过多将会产生严重的问题。每个分段都会消耗文件句柄，内存和CPU周期。更重要的是每个搜索请求必须按顺序查询各个分段，分段越多，查询就越慢。
	Elasticsearch通过在后台合并分段来解决这些问题。小的分段被合并进大的分段中，然后稍大的分段又会合并到更大的分段中。
	这就是哪些已经被删除的老文档从文件系统中被净化的时候。被删除的文档（或是旧版本的文档）是不会被拷贝到新的、更大的分段中的。
	合并的进程是在你索引和搜索的时候自动执行的，不要任何配置。它的工作进程如下：
	1.当索引的时候，刷新进程创建新的分段并且将它们打开以满足搜索需求
	2.合并进程在后台挑出部分小的分段，然后把它们合并到一个大的分段中去。这些操作不会打断正在进行的索引和搜索。
	3.1 新的分段被冲刷到硬盘中
	3.2 包含此分段的新的提交点被写入，被合并掉的老分段会不会包含在提交点中
	3.3 新的分段被打开
	3.4 就的分段被删除
	如果不做检查的话，大分段的合并可能会耗费大量的I/O和CPU,这将会损害到搜索的性能。默认情况下，Elasticsearch会对合并进程做节制以保证性能不会受到过大的影响。
	optimize API的最佳描述是：强制合并API。它强制分片把分段的数量合并到max_num_segments参数规定的数量，意图是减少分段的数量来提高搜索性能。
	optimize API不能被用于一个动态的索引（经常被更新），optimize API会将原本在后台执行的自动合并进程隐藏，所以一定要注意。
	在特定的情况下，optimize API是很有用的。典型的应用就是日志，日志是按照年月日来存储的。旧的索引都是只读的，不太可能会改变。
	在这种情况下，对于老的索引，把分段优化为只有一个的话还是很有用的：
	POST /logstash-2014-10/_optimize?max_num_segments=1 
	需要注意的是，通过optimize API执行的合并是不会被限制的，它会消耗所有的I/O资源，这是其它功能就没有资源可用的，如果你要再一个索引上使用优化的话，你要使用分片位置重置先把索引移动到一个可以安全运行的节点上。
