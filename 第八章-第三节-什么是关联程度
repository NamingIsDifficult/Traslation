	之前我们有提到说默认情况下结果是按照关联程度降序返回的。那么关联程度的定义是什么，又是怎么计算的呢？
	每个文档相对查询的关联程度的分数是通过一个正浮点数_score表示的。_score越高，关联程度越大。
	一个查询子句为每个文档都生成了一个_score字段。分数如何计算取决于查询子句的类型。不同的查询子句使用的场景和目的各不相同：一个fuzzy查询可能会决定通过找到的单词与原始搜索短语的相似程度来计算；一个terms查询会将找到的短语进行概率统计。但是，通常意义下的关联程度是指计算全文本字段的文本与全文本查询字串的相似程度的算法。
	Elasticsearch中的标准相似度算法是短语频率/反响索引文档频率算法，也叫做TF/IDF，在计算中需要以下参数：
	短语频率：
		这个短语在字段中出现的次数是多少？越多则关联度越大。提及这个短语越多次的字段要比相对少的字段更加有关联。
	反向索引文档频率：
		每个短语在索引中出现的次数是多少？越多则关联度越小。在许多文档中都出现的短语权重会比不那么寻常的短语低。
	字段长度规范：
		字段的长度是多少？越长的话，其中的字段关联程度就可能越小。一个在较短的字段中出现的短语所占权重要比它在较长字段中出现来的高。
	个别的查询可能会将TF/IDF评分和其他参数整合在一起，比如在词组查询中的短语的邻近程度，或者模糊查询中短语的相似程度。
	关联程度不仅仅能用于全文本搜索，它也可以被用于布尔型的子句，越多的子句匹配的话，评分也越高。
	当使用类似bool查询这样的联合搜索子句的时候，每个子句的_score将会被用于计算整体的_score。
	当要对一个复杂的查询debug的时候，理解_score是如何被计算出来的是比较困难的。Elasticsearch有可以生成此类解释的选项，可以通过设置explain参数为true来获取解释：
	GET /_search?explain //每个文档的_score计算结果的解释都会返回
	{
	   "query"   : { "match" : { "tweet" : "honeymoon" }}
	}
	在元数据字段之后会添加关于文档所在分片和节点的信息，由于短语和文档的频率是按照分片而不是索引来计算的，所以这个信息非常的有用。
	{
	    "_index" :      "us",
	    "_type" :       "tweet",
	    "_id" :         "12",
	    "_score" :      0.076713204,
	    "_source" :     { ... trimmed ... },   
	    "_shard" :      1,
    	"_node" :       "mzIVYCsqSWCG_M_ZffSs9Q",
    然后是_explanation。每个入口都包含一个description来告诉你实施的是哪种计算，value字段显示计算的结果，details字段显示了其中的子计算情况：
    "_explanation": { 
	   "description": "weight(tweet:honeymoon in 0)
	                  [PerFieldSimilarity], result of:",
	   "value":       0.076713204,
	   "details": [
	      {
	         "description": "fieldWeight in 0, product of:",
	         "value":       0.076713204,
	         "details": [
	            {  
	               "description": "tf(freq=1.0), with freq of:",//短语频率
	               "value":       1,
	               "details": [
	                  {
	                     "description": "termFreq=1.0",
	                     "value":       1
	                  }
	               ]
	            },
	            { 
	               "description": "idf(docFreq=1, maxDocs=1)",//反向索引文档频率
	               "value":       0.30685282
	            },
	            { 
	               "description": "fieldNorm(doc=0)",//字段长度规范
	               "value":        0.25,
	            }
	         ]
	      }
	   ]
	}
	生成解释的代价高昂，所以只用于排错时使用，千万不要在生产环境使用。
	解释的第一部分是计算结果的总结，它告诉我们它使用TF/IDF计算了文档0中honeymoon短语在tweet字段中的的权重，0是内部的文档id，对于本章的教学而言可以忽略。
	然后则是权重计算的细节，即短语频率计算、反向索引文档频率计算、字段长度规范。
	对于更加复杂的查询，它所产生的解释可能会非常的复杂，不过实际上，它们也不过是前文所展示的例子中的解释的复合体罢了。这些解释对于debug查询结果的排序非常的有用。
	explain的输出使用JSON来展示的时候可读性比较差，不过如果使用YAML格式来展示的话可读性大大提高。使用参数format=yaml可以转换格式。
	当explain选项对每个结果都添加了解释的时候，你可以使用explain API来理解为什么一个特定的文档会匹配，或者不匹配的原因。
	如下查询：
	GET /us/tweet/12/_explain
	{
	   "query" : {
	      "filtered" : {
	         "filter" : { "term" :  { "user_id" : 2           }},
	         "query" :  { "match" : { "tweet" :   "honeymoon" }}
	      }
	   }
	}
	返回中的解释如下
	"failure to match filter: cache(user_id:[2 TO 2])"
	也就是说user_id=2这个过滤子句没有通过导致文档不匹配。
