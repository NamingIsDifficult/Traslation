	mget和bulk之类的批量操作API和操作单个文档的方式是相似的。不同之处在于协作节点知道每个文档在哪个分片中。它按照分片将请求拆分为多个小的请求，然后平行的将这些请求发送给关联的各个节点。
	协作节点一旦从所有关联节点那里接收到响应，它会将所有响应在整理为一个响应，然后返回给客户端，举例来看mget的执行步骤：
	1：客户端发送mget请求给协作节点
	2：协作节点按照分片将请求拆分多个批量获取请求，然后平行转发给相应的节点，等所有的节点返回之后，在将响应整理为一个并返回个客户端。
	每一个docs数组中都可以加入一个routing的参数。
	bulk API的执行步骤如下：
	1：客户端发送bulk请求到协作节点
	2：协作节点按照分片拆分出多个bulk请求，然后在平行转发给拥有相应基本分片的节点
	3：基本分片连续的执行每个动作，一个动作成功之后，基本分片再将新文档平行的转发给它的复制分片，然后再执行下一个动作。所有的复制分片都返回成功之后，目标节点向协作节点返回成功状态，协作节点在整理各个节点的返回信息然后返回给客户端。
	bulk API也接受consistency和routing参数。
	之前有介绍过bulk API，并且提到过它的请求格式比较奇怪，为什么不能像mget一样发送一个JSON数组呢？
	这里需要对一些背景情况做下介绍：bulk API中的每个文档都有可能属于不同的基本分片，属于不同的节点。也就是说请求中的每个动作都需要被转发到正确的分片和正确的节点。
	如果单独的请求被包含在一个JSON数组中，那么意味着要做以下事情：
	1，将JSON解析成一个数组（包含文档数据，可能超大）
	2，遍历请求来决定转发到哪个分片
	3，为每个分片创建一个请求数组
	4，将这些数组序列化成内部通信的格式
	5，将请求发送到各个分片
	这也没有什么问题，但是将会消耗许多的内存来存储相同数据的多个拷贝，并且会创建更多地对象，使得垃圾回收更加频繁。
	Elasticsearch将这个步骤提前到了网络缓冲阶段，这里原始请求被接收，然后可以直接读取数据，它是用换行符来做标志，并且只需要解析包含元数据的那一部分，只需要这部分就可以处理转发步骤了。
	这些原始请求将会被原样转发给正确的分片，这样就不会有多余重复的数据产生了，也没有多余的序列化反序列化，整个请求耗费的资源相应就少了许多。
